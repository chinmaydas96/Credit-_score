{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cs1 - train_dataset.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>d_open</th>\n",
       "      <th>d_start</th>\n",
       "      <th>d_last</th>\n",
       "      <th>d_close</th>\n",
       "      <th>client_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>interest</th>\n",
       "      <th>period</th>\n",
       "      <th>category</th>\n",
       "      <th>cur</th>\n",
       "      <th>overdue</th>\n",
       "      <th>pmt_due</th>\n",
       "      <th>amt_paid</th>\n",
       "      <th>amt_overdue</th>\n",
       "      <th>max_overdue</th>\n",
       "      <th>delay</th>\n",
       "      <th>npl_5</th>\n",
       "      <th>npl_5_29</th>\n",
       "      <th>npl_30</th>\n",
       "      <th>npl_30_59</th>\n",
       "      <th>npl_60_89</th>\n",
       "      <th>npl_90plus</th>\n",
       "      <th>pmt_history</th>\n",
       "      <th>bki_id</th>\n",
       "      <th>d_request</th>\n",
       "      <th>d_confirm</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12608</td>\n",
       "      <td>40425</td>\n",
       "      <td>40611.0</td>\n",
       "      <td>42251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>146398</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>810</td>\n",
       "      <td>1360357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172778.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11111111</td>\n",
       "      <td>1</td>\n",
       "      <td>40641</td>\n",
       "      <td>40610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17459</td>\n",
       "      <td>40344</td>\n",
       "      <td>40497.0</td>\n",
       "      <td>41440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XAA110</td>\n",
       "      <td>3</td>\n",
       "      <td>40501</td>\n",
       "      <td>40475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10050</td>\n",
       "      <td>40279</td>\n",
       "      <td>40489.0</td>\n",
       "      <td>72697.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>810</td>\n",
       "      <td>12941.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>X1111111</td>\n",
       "      <td>3</td>\n",
       "      <td>40495</td>\n",
       "      <td>40488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16804</td>\n",
       "      <td>40121</td>\n",
       "      <td>40305.0</td>\n",
       "      <td>40304.0</td>\n",
       "      <td>40305.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111111</td>\n",
       "      <td>3</td>\n",
       "      <td>40581</td>\n",
       "      <td>40313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19775</td>\n",
       "      <td>39603</td>\n",
       "      <td>40029.0</td>\n",
       "      <td>39933.0</td>\n",
       "      <td>40029.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234469.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXXXXXXXXXXXXX</td>\n",
       "      <td>3</td>\n",
       "      <td>40511</td>\n",
       "      <td>40473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  d_open  d_start   d_last  d_close  client_type  loan_purpose  \\\n",
       "0      12608   40425  40611.0  42251.0      NaN            1             9   \n",
       "1      17459   40344  40497.0  41440.0      NaN            1             9   \n",
       "2      10050   40279  40489.0  72697.0      NaN            1             7   \n",
       "3      16804   40121  40305.0  40304.0  40305.0            1             9   \n",
       "4      19775   39603  40029.0  39933.0  40029.0            1             7   \n",
       "\n",
       "   max_amount  interest period  category  cur    overdue  pmt_due  amt_paid  \\\n",
       "0      146398         0      3         0  810  1360357.0      NaN       NaN   \n",
       "1      250000         0      0         0  810        NaN      NaN   42600.0   \n",
       "2       15000         0      3         0  810    12941.0    280.0    6146.0   \n",
       "3       11490         0      0        13  810        0.0      NaN       0.0   \n",
       "4      200000         0      3        13  810        NaN      0.0  234469.0   \n",
       "\n",
       "   amt_overdue  max_overdue  delay  npl_5  npl_5_29  npl_30  npl_30_59  \\\n",
       "0          0.0     172778.0    0.0      1         0       1          0   \n",
       "1          0.0          0.0   29.0      0         2       2          0   \n",
       "2          0.0          0.0    0.0      0         0       0          0   \n",
       "3          0.0          0.0    NaN      0         0       0          0   \n",
       "4          0.0          0.0    NaN      0         0       0          0   \n",
       "\n",
       "   npl_60_89  npl_90plus      pmt_history  bki_id  d_request  d_confirm  \\\n",
       "0          0           0         11111111       1      40641      40610   \n",
       "1          0           0           XAA110       3      40501      40475   \n",
       "2          0           0         X1111111       3      40495      40488   \n",
       "3          0           0          1111111       3      40581      40313   \n",
       "4          0           0  XXXXXXXXXXXXXXX       3      40511      40473   \n",
       "\n",
       "   default  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatype and missing value of each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135000 entries, 0 to 134999\n",
      "Data columns (total 29 columns):\n",
      "client_id       135000 non-null int64\n",
      "d_open          135000 non-null int64\n",
      "d_start         127379 non-null float64\n",
      "d_last          126170 non-null float64\n",
      "d_close         66120 non-null float64\n",
      "client_type     135000 non-null int64\n",
      "loan_purpose    135000 non-null int64\n",
      "max_amount      135000 non-null int64\n",
      "interest        135000 non-null int64\n",
      "period          134901 non-null object\n",
      "category        135000 non-null int64\n",
      "cur             135000 non-null object\n",
      "overdue         108872 non-null float64\n",
      "pmt_due         61524 non-null float64\n",
      "amt_paid        49294 non-null float64\n",
      "amt_overdue     134985 non-null float64\n",
      "max_overdue     134985 non-null float64\n",
      "delay           109435 non-null float64\n",
      "npl_5           135000 non-null int64\n",
      "npl_5_29        135000 non-null int64\n",
      "npl_30          135000 non-null int64\n",
      "npl_30_59       135000 non-null int64\n",
      "npl_60_89       135000 non-null int64\n",
      "npl_90plus      135000 non-null int64\n",
      "pmt_history     130657 non-null object\n",
      "bki_id          135000 non-null int64\n",
      "d_request       135000 non-null int64\n",
      "d_confirm       135000 non-null int64\n",
      "default         135000 non-null int64\n",
      "dtypes: float64(9), int64(17), object(3)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['client_type','loan_purpose','max_amount','interest','category','overdue','max_overdue','delay','npl_5','npl_5_29','npl_30','npl_30_59','npl_60_89','npl_90plus','default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135000 entries, 0 to 134999\n",
      "Data columns (total 15 columns):\n",
      "client_type     135000 non-null int64\n",
      "loan_purpose    135000 non-null int64\n",
      "max_amount      135000 non-null int64\n",
      "interest        135000 non-null int64\n",
      "category        135000 non-null int64\n",
      "overdue         108872 non-null float64\n",
      "max_overdue     134985 non-null float64\n",
      "delay           109435 non-null float64\n",
      "npl_5           135000 non-null int64\n",
      "npl_5_29        135000 non-null int64\n",
      "npl_30          135000 non-null int64\n",
      "npl_30_59       135000 non-null int64\n",
      "npl_60_89       135000 non-null int64\n",
      "npl_90plus      135000 non-null int64\n",
      "default         135000 non-null int64\n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 15.4 MB\n"
     ]
    }
   ],
   "source": [
    "# See Distribution\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which have max missing values\n",
    "\n",
    "df = df.dropna(subset=['delay','overdue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83641\n",
       "1     9677\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['default'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spilt the dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 80% data as traing set and 20% as testing set\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    66891\n",
       "1     7761\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set distribution\n",
    "\n",
    "train['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16750\n",
       "1     1916\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing set distribution\n",
    "\n",
    "test['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "\n",
    "y_test = test.default\n",
    "X_test = test.drop('default', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Apply Logistic Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "labels = train.default\n",
    "features = train.drop('default', axis=1)\n",
    "\n",
    "# Train model\n",
    "clf_0 = LogisticRegression().fit(features, labels)\n",
    " \n",
    "# Predict on testing set\n",
    "pred_y_0 = clf_0.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8973534769098896\n"
     ]
    }
   ],
   "source": [
    "# How's the accuracy?\n",
    "print( accuracy_score(pred_y_0, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix \n",
    "\n",
    "TP TN\n",
    "\n",
    "\n",
    "FP FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16750,  1916],\n",
       "       [    0,     0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred_y_0, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roc Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5230723522263422\n"
     ]
    }
   ],
   "source": [
    "prob_y_0 = clf_0.predict_proba(X_test)\n",
    "prob_y_0 = [p[1] for p in prob_y_0]\n",
    " \n",
    "print( roc_auc_score(y_test, prob_y_0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only '0' class predicted as we have uneven distibution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print( np.unique( pred_y_0 ) )\n",
    "# [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Sampling method to make equal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Up-sample Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = train[train.default==0]\n",
    "df_minority = train[train.default==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66891, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_majority.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=66924,    # to match majority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    66924\n",
       "0    66891\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_upsampled['default']\n",
    "features = df_upsampled.drop(['default'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.8709418193506911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# Train model\n",
    "clf_1 = LogisticRegression().fit(features, labels)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_1 = clf_1.predict(X_test)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_1 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y_test, pred_y_1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5358999158695043\n"
     ]
    }
   ],
   "source": [
    "# What about Area Under ROC?\n",
    "prob_y_1 = clf_1.predict_proba(X_test)\n",
    "prob_y_1 = [p[1] for p in prob_y_1]\n",
    "print( roc_auc_score(y_test, prob_y_1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slightly better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16171,   579],\n",
       "       [ 1830,    86]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Down-sample Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = train[train.default==0]\n",
    "df_minority = train[train.default==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7761, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_minority.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=7680,     # to match minority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7761\n",
       "0    7680\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.721257902067931\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "labels = df_downsampled.default\n",
    "features = df_downsampled.drop('default', axis=1)\n",
    " \n",
    "    \n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "    \n",
    "    \n",
    "# Train model\n",
    "clf_2 = LogisticRegression()\n",
    "clf_2.fit(features, labels)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_2 = clf_2.predict(X_test)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_2 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y_test, pred_y_2) )\n",
    "# 0.581632653061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538518929361543\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "prob_y_2 = clf_2.predict_proba(X_test)\n",
    " \n",
    "# Keep only the positive class\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "\n",
    "print( roc_auc_score(y_test, prob_y_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12918,  3832],\n",
       "       [ 1371,   545]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_y_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Penalize Algorithms (Cost-Sensitive Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#```Python\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "#labels = train.default\n",
    "#features = train.drop('default', axis=1)\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)    \n",
    "\n",
    "# Train model\n",
    "clf_3 = SVC(kernel='linear', \n",
    "            class_weight='balanced', # penalize\n",
    "            probability=True)\n",
    "\n",
    "clf_3.fit(features, labels)\n",
    "\n",
    "# Predict on training set\n",
    "pred_y_3 = clf_3.predict(X_test)\n",
    "\n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_3 ) )\n",
    "# [0 1]\n",
    "\n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y_test, pred_y_3) )\n",
    "\n",
    "\n",
    "# What about AUROC?\n",
    "prob_y_3 = clf_3.predict_proba(X_test)\n",
    "prob_y_3 = [p[1] for p in prob_y_3]\n",
    "print( roc_auc_score(y_test, prob_y_3) )\n",
    "#```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Use Tree-Based Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.5804671595414121\n",
      "0.5942468295266881\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "#labels = train.default\n",
    "#features = train.drop('default', axis=1)\n",
    " \n",
    "    \n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)   \n",
    " \n",
    "# Train model\n",
    "clf_4 = RandomForestClassifier()\n",
    "clf_4.fit(features, labels)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_4 = clf_4.predict(X_test)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_4 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y_test, pred_y_4) )\n",
    "\n",
    "# What about AUROC?\n",
    "prob_y_4 = clf_4.predict_proba(X_test)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print( roc_auc_score(y_test, prob_y_4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Result with downsampling and decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9760, 6990],\n",
       "       [ 841, 1075]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_y_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
